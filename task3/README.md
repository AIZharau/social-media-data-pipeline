# Задание 3: Оптимизированная обработка данных о заказах

## Описание решения

Данный проект представляет собой ETL-систему для эффективной загрузки, нормализации и анализа данных о заказах пользователей. Система включает в себя:

1. **Асинхронный ETL-скрипт для загрузки и нормализации данных**
   - Эффективная загрузка CSV-файла с помощью pandas
   - Нормализация данных (выделение справочных таблиц)
   - Пакетная загрузка (COPY) для максимальной производительности
   - Асинхронный ввод-вывод с использованием asyncpg

2. **Оптимизированная схема базы данных**
   - Разделение на нормализованные таблицы: subjects, courses, packages, orders
   - Партиционирование таблицы orders по дате для повышения производительности
   - Оптимальные индексы для частых запросов

3. **Оптимизированные SQL-запросы для аналитики**
   - ТОП-5 самых продаваемых курсов по месяцам
   - ТОП-3 самых популярных пакетов по предметам
   - Дополнительные аналитические запросы для бизнес-метрик

## Требования

- Python 3.8+
- PostgreSQL 12+
- Библиотеки Python: asyncpg, pandas, asyncio

## Установка и настройка

1. **Установка зависимостей**:
   ```bash
   pip install asyncpg pandas
   ```

2. **Создание базы данных в PostgreSQL**:
   ```bash
   createdb orders_db
   ```

3. **Настройка параметров PostgreSQL для оптимальной загрузки**:
   ```sql
   ALTER SYSTEM SET work_mem = '64MB';
   ALTER SYSTEM SET maintenance_work_mem = '512MB';
   ALTER SYSTEM SET checkpoint_timeout = '30min';
   ALTER SYSTEM SET max_wal_size = '4GB';
   ALTER SYSTEM SET synchronous_commit = 'off';
   ALTER SYSTEM SET wal_buffers = '16MB';
   ALTER SYSTEM RESET synchronous_commit; -- После загрузки!
   
   -- Перезагрузка конфигурации
   SELECT pg_reload_conf();
   ```

## Использование

### Загрузка данных

```bash
python etl_loader.py --input path/to/orders.csv --dbname orders_db --user postgres --password postgres --batch-size 10000
```

### Анализ данных

Запустите SQL-запросы из файла `sql/analysis_queries.sql` для получения аналитических отчетов:

1. **ТОП-5 самых продаваемых курсов по месяцам**:
   ```sql
   -- См. первый запрос в sql/analysis_queries.sql
   ```

2. **ТОП-3 самых популярных пакетов по предметам**:
   ```sql
   -- См. второй запрос в sql/analysis_queries.sql
   ```

## Оптимизация производительности

### 1. Оптимизация загрузки данных:

- **Параметры БД для оптимизации**:
   - `work_mem`: Увеличение до 64-128MB ускоряет сортировку и агрегацию
   - `shared_buffers`: Рекомендуется 25% от общей памяти системы
   - `maintenance_work_mem`: Увеличение до 512MB-1GB ускоряет создание индексов
   - `synchronous_commit=off`: Временное отключение при загрузке увеличивает скорость в 2-3 раза
   - `max_wal_size`: Увеличение до 4GB уменьшает частоту контрольных точек
   - `checkpoint_timeout`: Увеличение до 30min сокращает I/O при массовой загрузке

- **Избегание блокировок таблиц**:
   - Загрузка данных в новые таблицы (а не в существующие)
   - Создание индексов ПОСЛЕ загрузки данных
   - Использование опции CONCURRENTLY при создании индексов в рабочей системе
   - Партиционирование таблиц для разделения блокировок по секциям
   - Транзакции оптимальной величины (не слишком большие, не слишком маленькие)

### 2. Оптимизация хранения:

- **Партиционирование по диапазону дат**: Таблица orders разделена по месяцам
- **Оптимальные индексы**:
  - Простые индексы для foreign keys и поисковых полей
  - Составные индексы для частых шаблонов запросов
  - Индекс по ключу партиционирования

### 3. Оптимизация запросов:

- **Использование оконных функций** для расчета рангов без подзапросов
- **Материализованные представления** для часто используемых агрегаций
- **Избегание full table scan** за счет правильных индексов
- **Использование механизма pruning партиций** через явное указание диапазонов дат

## Ответы на вопросы задания

### Как ускорить загрузку данных?

1. **Параметры БД для оптимизации**:
   - `work_mem`: Увеличение до 64-128MB ускоряет сортировку и агрегацию
   - `shared_buffers`: Рекомендуется 25% от общей памяти системы
   - `maintenance_work_mem`: Увеличение до 512MB-1GB ускоряет создание индексов
   - `synchronous_commit=off`: Временное отключение при загрузке увеличивает скорость в 2-3 раза
   - `max_wal_size`: Увеличение до 4GB уменьшает частоту контрольных точек
   - `checkpoint_timeout`: Увеличение до 30min сокращает I/O при массовой загрузке

2. **Избегание блокировок таблиц**:
   - Загрузка данных в новые таблицы (а не в существующие)
   - Создание индексов ПОСЛЕ загрузки данных
   - Использование опции CONCURRENTLY при создании индексов в рабочей системе
   - Партиционирование таблиц для разделения блокировок по секциям
   - Транзакции оптимальной величины (не слишком большие, не слишком маленькие)

### Стратегия партиционирования

Для данной задачи выбрано **партиционирование по диапазону (RANGE)** по полю `order_date`:
- **Преимущества**: Эффективно для временных данных, облегчает архивацию старых данных, оптимизирует запросы с фильтрацией по датам
- **Недостатки**: Может приводить к неравномерному распределению данных, если распределение заказов по времени неравномерно

### Минимизация full table scan

- Создание индексов, соответствующих частым запросам
- Использование составных индексов для запросов с несколькими условиями
- Партиционирование таблиц для уменьшения объема сканируемых данных
- Использование EXPLAIN ANALYZE для выявления и оптимизации неэффективных запросов 