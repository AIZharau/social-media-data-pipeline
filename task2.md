# **Задание 2:**
## **Работа с Big Data**: обработка событий в реальном времени
В системе поступает существенное количество событий в секунду (клики, просмотры, покупки). Вам нужно спроектировать масштабируемую систему для обработки и хранения этих данных.
### **Задачи**:
#### 1. Выбор технологий для обработки в реальном времени: 
- Kafka, Apache Flink, Spark Streaming, ClickHouse – какие инструменты использовать и почему?
- Какую архитектуру (Lambda/Kappa) выбрать?
#### 2. Хранилище агрегированных данных:
- Как организовать оптимальное хранилище (OLAP vs OLTP)?
- Какие базы данных использовать (Druid, ClickHouse, BigQuery, Redshift, Snowflake)?
- Как избежать нагрузки на БД при росте объема данных?
#### 3. Проектирование архитектуры:
- Нарисуйте архитектурную схему системы потоковой обработки (draw.io, Miro).
- Как организовать буферизацию данных и авто-маcштабирование?
- Какой механизм дедупликации событий предложите?
4. Автоматизация развертывания:
 - Как бы вы настроили CI/CD для Data Engineering?
- Какие инструменты мониторинга (DataDog, Prometheus) и логирования (ELK, OpenTelemetry) выберете и почему?


### **Решение: Архитектура системы обработки событий в реальном времени (Real-Time Event Processing)** 

## Выбранный технологический стек

### 1. Обработка в реальном времени
- **Apache Kafka** — высоконагруженный распределенный брокер сообщений
- **Apache Flink** — фреймворк для потоковой обработки данных с низкой задержкой

### 2. Хранение агрегированных данных
- **ClickHouse** — колоночная СУБД для аналитических запросов
- **S3 / MinIO** — хранилище сырых данных для долгосрочного хранения

### 3. Мониторинг и логирование
- **Prometheus + Grafana** — мониторинг системных метрик и производительности
- **ELK Stack** — централизованное логирование и анализ логов
- **OpenTelemetry** — трейсинг распределенных запросов

### 4. Автоматизация развертывания
- **Kubernetes** — управление контейнерами и оркестрация
- **Terraform** — инфраструктура как код
- **GitLab CI** — автоматизация сборки и деплоя

## Архитектура системы


![Архитектура системы](./migrations/egland2.png)

## Обоснование выбора

### 1. Архитектура Kappa
Выбрана **Kappa-архитектура** по следующим причинам:
- Единая логика обработки данных без дублирования кода для пакетной и потоковой обработки
- Отсутствие необходимости поддерживать две системы (batch и streaming)
- Возможность переигрывать исторические данные из персистентного хранилища Kafka

### 2. Apache Kafka + Apache Flink
Эта комбинация оптимальна для высоконагруженных систем, так как:
- Kafka обеспечивает высокую пропускную способность (миллионы сообщений в секунду)
- Flink предоставляет обработку с минимальной задержкой (true streaming, а не micro-batching)
- Гарантии exactly-once при обработке данных
- Встроенные механизмы управления состоянием и оконные агрегации

### 3. ClickHouse как OLAP-хранилище
ClickHouse выбран потому, что:
- Обеспечивает высокую скорость аналитических запросов (в 100-1000 раз быстрее традиционных СУБД)
- Поддерживает реальную агрегацию по времени для больших данных
- Эффективное сжатие данных (снижает затраты на хранение)
- Возможность шардирования для горизонтального масштабирования

### 4. Решение проблемы нагрузки на БД
- **Предагрегация данных в Flink** перед записью в ClickHouse
- **Кэширование горячих данных в Redis** для частых запросов
- **Партиционирование таблиц** по дате и типу события
- **Материализованные представления** в ClickHouse для ускорения повторяющихся запросов

### 5. Механизм дедупликации событий
- Уникальный идентификатор события (`event_id`) в каждом сообщении
- Использование stateful-операций в Flink для отслеживания уже обработанных событий
- Дополнительная проверка на уникальность в ClickHouse через агрегационные функции

### 6. Буферизация и масштабирование
- Kafka с настройками retention policy для контроля объема данных
- Автоскейлинг Flink-операторов в Kubernetes при росте нагрузки
- Шардирование и репликация в ClickHouse для распределения нагрузки чтения/записи

### 7. CI/CD для Data Engineering
- Управление инфраструктурой через Terraform (IaC)
- Автоматизация тестирования и деплоя Flink-заданий через GitLab CI
- Контроль версий схем данных и DDL-операций

## Преимущества предложенного решения

1. **Производительность** — обработка миллионов событий в секунду с минимальной задержкой
2. **Масштабируемость** — горизонтальное масштабирование всех компонентов
3. **Отказоустойчивость** — репликация данных и автоматическое восстановление
4. **Гибкость** — возможность изменения логики обработки без простоев
5. **Экономичность** — эффективное использование ресурсов благодаря предагрегации и сжатию

Эта архитектура обеспечивает оптимальный баланс между стоимостью, производительностью и сложностью эксплуатации для обработки больших объемов данных в реальном времени. 